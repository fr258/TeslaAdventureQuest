[2021-02-22 00:06:08,637] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2021-02-22 00:06:08,684] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../logs, -Dlog4j.configuration=file:./kafka_2.13-2.7.0/bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_281, 25.281-b09
	jvm.classpath = /home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/org:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar
	os.spec = Linux, amd64, 4.4.0-103-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2021-02-22 00:06:08,691] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2021-02-22 00:06:08,809] INFO Loading plugin from: /home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-02-22 00:06:15,490] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:06:15,494] INFO Added plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:15,495] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:15,496] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:15,496] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:15,497] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:15,498] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,307] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:06:21,308] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,309] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,309] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,310] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,315] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,316] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,316] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,317] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,318] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,318] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,319] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,320] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,321] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,322] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,323] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,323] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,324] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,325] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,325] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,326] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,327] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,328] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,328] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,329] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,329] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,330] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,330] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,331] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,332] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,333] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,333] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,334] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,335] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,336] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,337] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,337] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,338] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,339] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,340] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,340] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,341] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,342] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,343] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,344] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,344] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,345] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,345] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:06:21,351] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,352] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,354] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,356] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,357] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,358] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,359] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,360] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,361] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,362] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,362] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,363] INFO Added aliases 'RocksetSinkConnector' and 'RocksetSink' to plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,364] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,365] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,365] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,366] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,367] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,368] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,368] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,369] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,370] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,370] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,371] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,371] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,372] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,373] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,373] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,374] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,375] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,376] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,377] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,379] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,381] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,384] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,385] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,387] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,388] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,388] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,389] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:06:21,390] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,391] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,392] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:06:21,500] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [kafka-connect-rockset-1.2.0-jar-with-dependencies.jar]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:361)
[2021-02-22 00:06:21,503] INFO Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:06:21,504] INFO Worker configuration property 'internal.key.converter.schemas.enable' (along with all configuration for 'internal.key.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:06:21,505] INFO Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:06:21,506] INFO Worker configuration property 'internal.value.converter.schemas.enable' (along with all configuration for 'internal.value.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:06:21,514] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-02-22 00:06:21,536] INFO AdminClientConfig values: 
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-02-22 00:06:22,335] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:06:23,496] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,497] WARN The configuration 'consumer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,498] WARN The configuration 'producer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,498] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,499] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,499] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,499] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,500] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,500] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,501] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,501] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,502] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,502] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,503] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,503] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,504] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,504] WARN The configuration 'consumer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,505] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,505] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,506] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,507] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,507] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,507] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,508] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,508] WARN The configuration 'producer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:06:23,511] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:06:23,512] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:06:23,512] INFO Kafka startTimeMs: 1613970383509 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:06:27,505] INFO Kafka cluster ID: lkc-863j0 (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-02-22 00:06:27,510] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:06:27,560] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:06:27,561] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:06:27,562] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:06:27,620] INFO Logging initialized @21131ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2021-02-22 00:06:27,869] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2021-02-22 00:06:27,871] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2021-02-22 00:06:27,917] INFO jetty-9.4.33.v20201020; built: 2020-10-20T23:39:24.803Z; git: 1be68755656cef678b79a2ef1c2ebbca99e25420; jvm 1.8.0_281-b09 (org.eclipse.jetty.server.Server:375)
[2021-02-22 00:06:28,006] ERROR Stopping due to error (org.apache.kafka.connect.cli.ConnectStandalone:130)
org.apache.kafka.connect.errors.ConnectException: Unable to initialize REST server
	at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:216)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:87)
Caused by: java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:8083
	at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:349)
	at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:310)
	at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at org.eclipse.jetty.server.Server.doStart(Server.java:401)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:72)
	at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:214)
	... 1 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:444)
	at sun.nio.ch.Net.bind(Net.java:436)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:225)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:345)
	... 8 more
[2021-02-22 00:08:26,347] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2021-02-22 00:08:26,384] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../logs, -Dlog4j.configuration=file:./kafka_2.13-2.7.0/bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_281, 25.281-b09
	jvm.classpath = /home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/org:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar
	os.spec = Linux, amd64, 4.4.0-103-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2021-02-22 00:08:26,391] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2021-02-22 00:08:26,524] INFO Loading plugin from: /home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-02-22 00:08:33,357] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:08:33,361] INFO Added plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:33,363] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:33,365] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:33,366] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:33,367] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:33,368] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,540] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:08:38,541] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,542] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,543] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,543] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,548] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,549] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,550] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,550] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,551] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,552] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,552] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,553] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,554] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,554] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,555] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,556] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,556] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,557] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,558] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,558] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,559] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,560] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,560] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,561] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,562] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,562] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,563] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,564] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,565] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,565] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,566] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,566] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,567] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,568] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,568] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,569] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,569] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,570] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,571] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,571] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,572] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,573] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,573] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,574] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,575] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,575] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,576] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:08:38,580] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,581] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,582] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,583] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,585] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,587] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,588] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,588] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,589] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,590] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,591] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,593] INFO Added aliases 'RocksetSinkConnector' and 'RocksetSink' to plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,594] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,595] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,596] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,597] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,598] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,598] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,599] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,600] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,601] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,602] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,603] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,604] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,604] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,605] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,606] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,607] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,608] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,609] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,611] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,612] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,614] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,616] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,617] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,617] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,618] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,618] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,619] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:08:38,619] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,620] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,620] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:08:38,716] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [kafka-connect-rockset-1.2.0-jar-with-dependencies.jar]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:361)
[2021-02-22 00:08:38,718] INFO Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:08:38,719] INFO Worker configuration property 'internal.key.converter.schemas.enable' (along with all configuration for 'internal.key.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:08:38,720] INFO Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:08:38,721] INFO Worker configuration property 'internal.value.converter.schemas.enable' (along with all configuration for 'internal.value.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:08:38,725] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-02-22 00:08:38,743] INFO AdminClientConfig values: 
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-02-22 00:08:43,039] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:08:44,303] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,304] WARN The configuration 'consumer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,305] WARN The configuration 'producer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,305] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,306] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,306] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,306] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,307] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,307] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,308] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,308] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,309] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,309] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,310] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,310] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,311] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,311] WARN The configuration 'consumer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,312] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,312] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,313] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,313] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,314] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,314] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,315] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,315] WARN The configuration 'producer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:44,318] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:08:44,318] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:08:44,319] INFO Kafka startTimeMs: 1613970524316 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:08:49,810] INFO Kafka cluster ID: lkc-863j0 (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-02-22 00:08:49,814] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:08:49,865] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:08:49,866] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:08:49,867] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:08:49,936] INFO Logging initialized @25448ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2021-02-22 00:08:50,178] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2021-02-22 00:08:50,179] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2021-02-22 00:08:50,213] INFO jetty-9.4.33.v20201020; built: 2020-10-20T23:39:24.803Z; git: 1be68755656cef678b79a2ef1c2ebbca99e25420; jvm 1.8.0_281-b09 (org.eclipse.jetty.server.Server:375)
[2021-02-22 00:08:50,344] INFO Started http_8083@497570fb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2021-02-22 00:08:50,346] INFO Started @25859ms (org.eclipse.jetty.server.Server:415)
[2021-02-22 00:08:50,463] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:08:50,463] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2021-02-22 00:08:50,465] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:08:50,465] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2021-02-22 00:08:50,466] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:08:50,468] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2021-02-22 00:08:50,516] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-02-22 00:08:50,519] INFO AdminClientConfig values: 
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-02-22 00:08:50,529] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:08:50,552] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,552] WARN The configuration 'consumer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,553] WARN The configuration 'producer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,553] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,554] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,555] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,555] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,555] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,556] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,556] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,557] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,557] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,558] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,558] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,559] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,560] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,560] WARN The configuration 'consumer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,561] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,561] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,562] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,562] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,563] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,564] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,564] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,565] WARN The configuration 'producer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:08:50,565] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:08:50,566] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:08:50,566] INFO Kafka startTimeMs: 1613970530565 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:08:55,372] INFO Kafka cluster ID: lkc-863j0 (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-02-22 00:08:55,374] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:08:55,398] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:08:55,399] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:08:55,400] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:08:55,418] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:08:55,419] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:08:55,420] INFO Kafka startTimeMs: 1613970535418 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:08:56,129] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-02-22 00:08:56,135] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-02-22 00:08:56,175] INFO Kafka Connect standalone worker initialization took 29818ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2021-02-22 00:08:56,175] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2021-02-22 00:08:56,180] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2021-02-22 00:08:56,181] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:195)
[2021-02-22 00:08:56,184] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2021-02-22 00:08:56,196] INFO Worker started (org.apache.kafka.connect.runtime.Worker:202)
[2021-02-22 00:08:56,196] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2021-02-22 00:08:56,197] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2021-02-22 00:08:56,395] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2021-02-22 00:08:56,762] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2021-02-22 00:08:56,763] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2021-02-22 00:08:56,769] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2021-02-22 00:08:59,291] INFO Started o.e.j.s.ServletContextHandler@7c4fc2bf{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:916)
[2021-02-22 00:08:59,292] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2021-02-22 00:08:59,292] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2021-02-22 00:08:59,373] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-02-22 00:08:59,431] INFO Creating connector integration2 of type rockset.RocksetSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-02-22 00:08:59,434] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:08:59,437] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,462] INFO Instantiated connector integration2 with version 1.0 of type class rockset.RocksetSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-02-22 00:08:59,464] INFO Finished creating connector integration2 (org.apache.kafka.connect.runtime.Worker:310)
[2021-02-22 00:08:59,470] INFO Starting RocksetSinkConnector (rockset.RocksetSinkConnector:22)
[2021-02-22 00:08:59,473] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:08:59,474] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:08:59,483] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:08:59,486] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,499] INFO Creating task integration2-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:08:59,510] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:08:59,511] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,516] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:08:59,518] INFO Instantiated task integration2-0 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:08:59,525] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:08:59,527] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:08:59,528] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-0 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:08:59,528] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-0 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:08:59,530] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:08:59,552] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:08:59,553] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:08:59,555] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,612] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:08:59,655] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:08:59,822] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:08:59,823] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:08:59,823] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:08:59,824] INFO Kafka startTimeMs: 1613970539823 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:08:59,867] INFO Creating task integration2-1 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:08:59,871] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:08:59,873] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,873] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:08:59,874] INFO Instantiated task integration2-1 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:08:59,875] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:08:59,876] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:08:59,876] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-1 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:08:59,877] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-1 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:08:59,877] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-1 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:08:59,882] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:08:59,883] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:08:59,892] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:08:59,893] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,897] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:08:59,899] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:08:59,900] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:08:59,949] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:08:59,953] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:08:59,954] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:08:59,955] INFO Kafka startTimeMs: 1613970539953 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:08:59,970] INFO Creating task integration2-2 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:08:59,976] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:08:59,978] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:08:59,981] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:08:59,982] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:08:59,994] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:08:59,997] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:08:59,998] INFO Instantiated task integration2-2 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:08:59,998] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:08:59,999] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,000] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-2 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,000] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-2 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,001] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-2 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,009] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,011] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,013] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,022] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,063] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,063] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,064] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,064] INFO Kafka startTimeMs: 1613970540063 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,080] INFO Creating task integration2-3 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,081] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,086] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,087] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,089] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,089] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,093] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,094] INFO Instantiated task integration2-3 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,095] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,096] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,096] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-3 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,097] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-3 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,098] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-3 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,107] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,111] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,113] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,117] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,150] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,151] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,152] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,152] INFO Kafka startTimeMs: 1613970540151 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,174] INFO Creating task integration2-4 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,175] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,180] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,181] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,181] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,188] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,192] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,193] INFO Instantiated task integration2-4 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,194] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,196] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,197] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-4 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,198] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-4 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,199] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-4 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,205] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,208] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,210] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,215] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,250] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,251] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,252] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,252] INFO Kafka startTimeMs: 1613970540251 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,266] INFO Creating task integration2-5 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,272] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,276] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,277] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,279] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,279] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,283] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,284] INFO Instantiated task integration2-5 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,285] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,285] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,286] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-5 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,287] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-5 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,288] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-5 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,293] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,295] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,297] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,307] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,337] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,338] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,338] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,339] INFO Kafka startTimeMs: 1613970540338 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,421] INFO Creating task integration2-6 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,426] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,429] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,431] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,432] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,441] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,433] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,446] INFO Instantiated task integration2-6 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,447] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,448] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,449] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-6 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,450] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-6 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,451] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-6 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,458] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,462] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,466] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,476] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,520] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,521] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,522] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,522] INFO Kafka startTimeMs: 1613970540521 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,536] INFO Creating task integration2-7 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,538] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,549] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,550] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,551] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,555] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,563] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,564] INFO Instantiated task integration2-7 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,565] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,568] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,569] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-7 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,569] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-7 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,571] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-7 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,576] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,581] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,584] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,592] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,626] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,627] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,628] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,628] INFO Kafka startTimeMs: 1613970540627 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,644] INFO Creating task integration2-8 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,646] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,655] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,655] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,656] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,657] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,661] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,662] INFO Instantiated task integration2-8 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,662] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,663] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,664] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-8 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,664] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-8 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,665] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-8 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,672] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,674] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,678] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,682] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,712] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,713] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,714] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,715] INFO Kafka startTimeMs: 1613970540713 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,726] INFO Creating task integration2-9 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:09:00,732] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,734] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,735] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,737] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:09:00,739] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,740] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:09:00,741] INFO Instantiated task integration2-9 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:09:00,742] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,742] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:09:00,743] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task integration2-9 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:09:00,744] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task integration2-9 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:09:00,745] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task integration2-9 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:09:00,751] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:09:00,753] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:09:00,756] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = integration2
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:09:00,760] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-integration2-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-integration2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:09:00,794] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:09:00,795] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:09:00,796] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:09:00,796] INFO Kafka startTimeMs: 1613970540795 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:09:00,823] INFO Created connector integration2 (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2021-02-22 00:09:00,827] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:09:00,830] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://oyFc92WvoadaaEbsdn8Q1NJHzDjPd62l24dfGPNNv0HrEBJB6wUL8IbRX0sILxtT@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:09:00,831] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:09:00,905] INFO WorkerSinkTask{id=integration2-5} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,907] INFO WorkerSinkTask{id=integration2-8} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,905] INFO WorkerSinkTask{id=integration2-7} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,909] INFO WorkerSinkTask{id=integration2-4} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,910] INFO WorkerSinkTask{id=integration2-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,911] INFO WorkerSinkTask{id=integration2-1} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,910] INFO WorkerSinkTask{id=integration2-3} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,922] INFO WorkerSinkTask{id=integration2-2} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,912] INFO WorkerSinkTask{id=integration2-9} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:00,912] INFO WorkerSinkTask{id=integration2-6} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:09:01,555] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,556] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,562] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,563] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,563] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,578] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,615] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,631] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,640] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,646] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,648] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,650] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,650] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,659] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,666] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,678] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,700] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,701] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,720] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,744] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,759] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,762] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,768] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,794] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,794] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,799] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,811] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:01,871] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:09:01,874] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:09:01,881] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,552] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,559] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,657] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,662] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,664] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,677] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Finished assignment for group at generation 1: {connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e=Assignment(partitions=[questTopic-0, questTopic-1])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:09:02,755] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:02,759] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:02,763] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,807] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,807] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,809] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Finished assignment for group at generation 2: {connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd=Assignment(partitions=[]), connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982=Assignment(partitions=[]), connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936=Assignment(partitions=[questTopic-1]), connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e=Assignment(partitions=[questTopic-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:09:02,820] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,822] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,827] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,857] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,864] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=2, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:02,868] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=2, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:02,871] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:02,872] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,868] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,864] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=2, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:02,875] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:02,876] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,874] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:02,876] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=2, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:02,878] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,879] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:02,880] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,889] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,931] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:02,970] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,970] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,970] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,971] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,970] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,974] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,972] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,974] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,992] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Finished assignment for group at generation 3: {connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041=Assignment(partitions=[]), connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd=Assignment(partitions=[]), connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982=Assignment(partitions=[]), connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28=Assignment(partitions=[]), connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936=Assignment(partitions=[]), connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08=Assignment(partitions=[]), connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2=Assignment(partitions=[]), connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e=Assignment(partitions=[questTopic-1]), connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd=Assignment(partitions=[questTopic-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:09:02,992] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:02,997] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,061] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,061] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,063] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,062] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,062] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,066] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,066] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,064] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,064] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,064] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,064] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,063] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=3, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:09:03,063] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,072] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,071] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,071] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,070] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,076] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,069] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,068] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,067] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,067] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:09:03,079] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,075] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,074] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,073] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,082] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:09:03,141] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,144] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,146] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,168] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,169] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,177] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Finished assignment for group at generation 4: {connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041=Assignment(partitions=[]), connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd=Assignment(partitions=[]), connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982=Assignment(partitions=[]), connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28=Assignment(partitions=[]), connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936=Assignment(partitions=[]), connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08=Assignment(partitions=[]), connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2=Assignment(partitions=[]), connector-consumer-integration2-7-2c63bf0f-34a9-4bc7-9790-7709e707a1a0=Assignment(partitions=[]), connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e=Assignment(partitions=[questTopic-1]), connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd=Assignment(partitions=[questTopic-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:09:03,186] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,187] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,186] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-7-2c63bf0f-34a9-4bc7-9790-7709e707a1a0', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,186] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,187] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:09:03,262] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,263] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,263] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-7-2c63bf0f-34a9-4bc7-9790-7709e707a1a0', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,263] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,262] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,266] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,265] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[questTopic-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,268] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,265] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,269] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,268] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,268] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[questTopic-1]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,270] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,270] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,273] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,269] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,273] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,275] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,276] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,277] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,273] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,279] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,281] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Adding newly assigned partitions: questTopic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,281] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Adding newly assigned partitions: questTopic-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,298] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,300] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:09:03,301] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,302] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:09:03,303] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,302] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:09:03,356] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Found no committed offset for partition questTopic-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-02-22 00:09:03,376] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Found no committed offset for partition questTopic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-02-22 00:09:07,584] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Resetting offset for partition questTopic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b1-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 1 rack: 1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-02-22 00:09:07,619] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Resetting offset for partition questTopic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b5-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 5 rack: 2)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-02-22 00:33:49,999] INFO WorkerSinkTask{id=integration2-0} Committing offsets asynchronously using sequence number 149: {questTopic-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-02-22 00:35:45,319] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2021-02-22 00:35:45,322] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2021-02-22 00:35:45,339] INFO Stopped http_8083@497570fb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2021-02-22 00:35:45,341] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2021-02-22 00:35:45,347] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2021-02-22 00:35:45,348] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2021-02-22 00:35:45,350] INFO Stopping task integration2-0 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,351] INFO Stopping task integration2-1 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,352] INFO Stopping task integration2-2 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,355] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,355] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,357] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Revoke previously assigned partitions questTopic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-02-22 00:35:45,359] INFO Stopping task integration2-3 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,359] INFO [Consumer clientId=connector-consumer-integration2-0, groupId=connect-integration2] Member connector-consumer-integration2-0-f4410cdf-1ce5-49b6-ab50-c51e4d94bbcd sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,365] INFO Stopping task integration2-4 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,364] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,361] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,370] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,355] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,371] INFO [Consumer clientId=connector-consumer-integration2-3, groupId=connect-integration2] Member connector-consumer-integration2-3-efcb2e0f-d36b-4924-b5dd-6bdf524f9c08 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,369] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,369] INFO Stopping task integration2-5 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,372] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,371] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,375] INFO [Consumer clientId=connector-consumer-integration2-4, groupId=connect-integration2] Member connector-consumer-integration2-4-10dc8f2d-c4fd-4bd1-81dd-b2d12fae7936 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,371] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,375] INFO [Consumer clientId=connector-consumer-integration2-2, groupId=connect-integration2] Member connector-consumer-integration2-2-1a9a0817-bcef-4d42-b5bb-95afa5720041 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,374] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,374] INFO Stopping task integration2-6 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,377] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,378] INFO Stopping task integration2-7 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,376] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Revoke previously assigned partitions questTopic-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2021-02-22 00:35:45,380] INFO [Consumer clientId=connector-consumer-integration2-5, groupId=connect-integration2] Member connector-consumer-integration2-5-ba8c0906-4d70-44b1-83f7-27ea7eea7b28 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,378] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,381] INFO Stopping task integration2-8 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,381] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,383] INFO Stopping task integration2-9 (org.apache.kafka.connect.runtime.Worker:836)
[2021-02-22 00:35:45,382] INFO [Consumer clientId=connector-consumer-integration2-1, groupId=connect-integration2] Member connector-consumer-integration2-1-e45cfd8a-579c-4203-b9d8-9ce5bc44438e sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,382] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,384] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,383] INFO Stopping Rockset Kafka Connect Plugin, waiting for active tasks to complete (rockset.RocksetSinkTask:176)
[2021-02-22 00:35:45,387] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,383] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,388] INFO [Consumer clientId=connector-consumer-integration2-8, groupId=connect-integration2] Member connector-consumer-integration2-8-ada98d4e-f23e-4159-9d19-a40efd2583d2 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,387] INFO [Consumer clientId=connector-consumer-integration2-6, groupId=connect-integration2] Member connector-consumer-integration2-6-834249ef-67cf-41f0-a98c-bc0dfdaaa4bd sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,387] INFO Stopped Rockset Kafka Connect Plugin (rockset.RocksetSinkTask:178)
[2021-02-22 00:35:45,388] INFO [Consumer clientId=connector-consumer-integration2-7, groupId=connect-integration2] Member connector-consumer-integration2-7-2c63bf0f-34a9-4bc7-9790-7709e707a1a0 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,390] INFO [Consumer clientId=connector-consumer-integration2-9, groupId=connect-integration2] Member connector-consumer-integration2-9-69310ed2-a841-4445-a804-fd1d10fc3982 sending LeaveGroup request to coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1029)
[2021-02-22 00:35:45,439] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,440] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,441] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,440] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,441] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,443] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,443] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,445] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,441] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,441] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,447] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,444] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,448] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,450] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,456] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,466] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,467] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,469] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,470] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,470] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,475] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,476] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,476] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,477] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,477] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,477] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,479] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,480] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,480] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,484] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,541] INFO App info kafka.consumer for connector-consumer-integration2-7 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,557] INFO App info kafka.consumer for connector-consumer-integration2-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,583] INFO App info kafka.consumer for connector-consumer-integration2-6 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,589] INFO App info kafka.consumer for connector-consumer-integration2-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,598] INFO App info kafka.consumer for connector-consumer-integration2-5 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,600] INFO App info kafka.consumer for connector-consumer-integration2-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,604] INFO App info kafka.consumer for connector-consumer-integration2-8 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,607] INFO App info kafka.consumer for connector-consumer-integration2-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,610] INFO App info kafka.consumer for connector-consumer-integration2-9 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,612] INFO App info kafka.consumer for connector-consumer-integration2-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,679] INFO Stopping connector integration2 (org.apache.kafka.connect.runtime.Worker:387)
[2021-02-22 00:35:45,679] INFO Scheduled shutdown for WorkerConnector{id=integration2} (org.apache.kafka.connect.runtime.WorkerConnector:249)
[2021-02-22 00:35:45,680] INFO Completed shutdown for WorkerConnector{id=integration2} (org.apache.kafka.connect.runtime.WorkerConnector:269)
[2021-02-22 00:35:45,683] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:209)
[2021-02-22 00:35:45,685] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2021-02-22 00:35:45,686] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:35:45,686] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:35:45,687] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:35:45,689] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:35:45,689] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:230)
[2021-02-22 00:35:45,694] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2021-02-22 00:35:45,695] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2021-02-22 00:38:49,261] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:69)
[2021-02-22 00:38:49,299] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../logs, -Dlog4j.configuration=file:./kafka_2.13-2.7.0/bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_281, 25.281-b09
	jvm.classpath = /home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/activation-1.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/argparse4j-0.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/audience-annotations-0.5.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-cli-1.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/commons-lang3-3.8.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-api-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-basic-auth-extension-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-file-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-json-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-mirror-client-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-runtime-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/connect-transforms-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-api-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-locator-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/hk2-utils-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-core-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-databind-2.10.5.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.25.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javassist-3.26.0-GA.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jaxb-api-2.3.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-client-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-common-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-container-servlet-core-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-hk2-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-media-jaxb-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jersey-server-2.31.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-client-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-continuation-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-http-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-io-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-security-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-server-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlet-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-servlets-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jetty-util-9.4.33.v20201020.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/jopt-simple-5.0.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka_2.13-2.7.0-sources.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-clients-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-log4j-appender-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-raft-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-examples-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-scala_2.13-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-streams-test-utils-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/kafka-tools-2.7.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/log4j-1.2.17.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/lz4-java-1.7.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/maven-artifact-3.6.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/metrics-core-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-buffer-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-codec-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-handler-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-resolver-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-epoll-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/netty-transport-native-unix-common-4.1.51.Final.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/org:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/paranamer-2.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/plexus-utils-3.2.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/reflections-0.9.12.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/rocksdbjni-5.18.4.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-library-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/scala-reflect-2.13.3.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-api-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/snappy-java-1.1.7.7.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zookeeper-jute-3.5.8.jar:/home/farrah/Downloads/rocksters/kafka_2.13-2.7.0/bin/../libs/zstd-jni-1.4.5-6.jar
	os.spec = Linux, amd64, 4.4.0-103-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2021-02-22 00:38:49,306] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:78)
[2021-02-22 00:38:49,441] INFO Loading plugin from: /home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2021-02-22 00:38:56,519] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/farrah/Downloads/rocksters/kafka-connect-rockset-1.2.0-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:38:56,523] INFO Added plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:38:56,524] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:38:56,525] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:38:56,526] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:38:56,526] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:38:56,527] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,985] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2021-02-22 00:39:01,985] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,986] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,987] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,987] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,992] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,993] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,993] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,994] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,995] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,995] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,996] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,997] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,998] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,998] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,999] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:01,999] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,000] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,001] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,001] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,002] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,003] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,003] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,004] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,005] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,006] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,006] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,007] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,008] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,009] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,010] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,013] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,014] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,015] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,016] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,016] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,017] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,022] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,024] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,025] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,026] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,027] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,028] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,029] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,030] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,031] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,032] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,033] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2021-02-22 00:39:02,037] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,038] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,040] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,041] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,042] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,043] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,044] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,044] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,045] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,046] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,048] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,049] INFO Added aliases 'RocksetSinkConnector' and 'RocksetSink' to plugin 'rockset.RocksetSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,050] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,051] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,052] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,053] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,054] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,055] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,056] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,056] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,057] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,058] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,059] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,060] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,061] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,061] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,062] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,063] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,064] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,065] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,066] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,067] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,069] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,070] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,071] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,071] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,072] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,073] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,073] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2021-02-22 00:39:02,074] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,075] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,075] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:430)
[2021-02-22 00:39:02,186] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = [kafka-connect-rockset-1.2.0-jar-with-dependencies.jar]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:361)
[2021-02-22 00:39:02,188] INFO Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:39:02,189] INFO Worker configuration property 'internal.key.converter.schemas.enable' (along with all configuration for 'internal.key.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:39:02,190] INFO Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:39:02,191] INFO Worker configuration property 'internal.value.converter.schemas.enable' (along with all configuration for 'internal.value.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:389)
[2021-02-22 00:39:02,196] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-02-22 00:39:02,223] INFO AdminClientConfig values: 
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-02-22 00:39:05,337] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:39:06,508] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,509] WARN The configuration 'consumer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,510] WARN The configuration 'producer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,510] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,511] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,511] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,512] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,512] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,513] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,513] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,514] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,514] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,515] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,515] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,516] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,516] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,517] WARN The configuration 'consumer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,517] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,518] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,519] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,519] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,520] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,520] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,521] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,521] WARN The configuration 'producer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:06,524] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:06,525] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:06,526] INFO Kafka startTimeMs: 1613972346522 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:10,727] INFO Kafka cluster ID: lkc-863j0 (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-02-22 00:39:10,731] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:39:10,780] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:39:10,781] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:39:10,781] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:39:10,843] INFO Logging initialized @23461ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2021-02-22 00:39:11,104] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2021-02-22 00:39:11,105] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2021-02-22 00:39:11,141] INFO jetty-9.4.33.v20201020; built: 2020-10-20T23:39:24.803Z; git: 1be68755656cef678b79a2ef1c2ebbca99e25420; jvm 1.8.0_281-b09 (org.eclipse.jetty.server.Server:375)
[2021-02-22 00:39:11,276] INFO Started http_8083@497570fb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2021-02-22 00:39:11,279] INFO Started @23897ms (org.eclipse.jetty.server.Server:415)
[2021-02-22 00:39:11,385] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:39:11,386] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2021-02-22 00:39:11,387] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:39:11,388] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2021-02-22 00:39:11,388] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2021-02-22 00:39:11,390] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2021-02-22 00:39:11,428] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2021-02-22 00:39:11,431] INFO AdminClientConfig values: 
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:361)
[2021-02-22 00:39:11,438] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:39:11,461] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,462] WARN The configuration 'consumer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,463] WARN The configuration 'producer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,463] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,464] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,464] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,465] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,466] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,466] WARN The configuration 'sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,467] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,467] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,468] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,469] WARN The configuration 'ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,469] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,470] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,471] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,472] WARN The configuration 'consumer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,472] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,473] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,473] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,475] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,476] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,476] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,477] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,477] WARN The configuration 'producer.ssl.endpoint.identification.algorithm' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2021-02-22 00:39:11,478] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:11,479] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:11,479] INFO Kafka startTimeMs: 1613972351478 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:12,843] INFO Kafka cluster ID: lkc-863j0 (org.apache.kafka.connect.util.ConnectUtils:65)
[2021-02-22 00:39:12,845] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2021-02-22 00:39:12,867] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:668)
[2021-02-22 00:39:12,868] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:672)
[2021-02-22 00:39:12,869] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:678)
[2021-02-22 00:39:12,892] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:12,893] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:12,894] INFO Kafka startTimeMs: 1613972352892 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:13,659] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-02-22 00:39:13,665] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:361)
[2021-02-22 00:39:13,708] INFO Kafka Connect standalone worker initialization took 24437ms (org.apache.kafka.connect.cli.ConnectStandalone:100)
[2021-02-22 00:39:13,709] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2021-02-22 00:39:13,714] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2021-02-22 00:39:13,715] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:195)
[2021-02-22 00:39:13,718] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2021-02-22 00:39:13,730] INFO Worker started (org.apache.kafka.connect.runtime.Worker:202)
[2021-02-22 00:39:13,731] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2021-02-22 00:39:13,731] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2021-02-22 00:39:13,931] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2021-02-22 00:39:14,357] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2021-02-22 00:39:14,358] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2021-02-22 00:39:14,365] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2021-02-22 00:39:16,810] INFO Started o.e.j.s.ServletContextHandler@7c4fc2bf{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:916)
[2021-02-22 00:39:16,811] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2021-02-22 00:39:16,811] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2021-02-22 00:39:16,888] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:361)
[2021-02-22 00:39:16,944] INFO Creating connector QuestIntegration of type rockset.RocksetSinkConnector (org.apache.kafka.connect.runtime.Worker:274)
[2021-02-22 00:39:16,947] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:16,950] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:16,975] INFO Instantiated connector QuestIntegration with version 1.0 of type class rockset.RocksetSinkConnector (org.apache.kafka.connect.runtime.Worker:284)
[2021-02-22 00:39:16,976] INFO Finished creating connector QuestIntegration (org.apache.kafka.connect.runtime.Worker:310)
[2021-02-22 00:39:16,982] INFO Starting RocksetSinkConnector (rockset.RocksetSinkConnector:22)
[2021-02-22 00:39:16,985] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:16,986] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:16,994] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:16,996] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,007] INFO Creating task QuestIntegration-0 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,017] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,019] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,024] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,026] INFO Instantiated task QuestIntegration-0 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,032] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,033] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,034] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-0 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,034] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-0 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,036] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-0 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,058] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,060] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,061] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,115] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,160] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2021-02-22 00:39:17,342] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,343] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,343] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,344] INFO Kafka startTimeMs: 1613972357342 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,389] INFO Creating task QuestIntegration-1 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,395] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,397] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,398] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,399] INFO Instantiated task QuestIntegration-1 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,400] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,401] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,401] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-1 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,402] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-1 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,403] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-1 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,404] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,409] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,410] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,411] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,413] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,415] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,421] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,460] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,461] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,462] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,462] INFO Kafka startTimeMs: 1613972357461 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,476] INFO Creating task QuestIntegration-2 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,477] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,483] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,483] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,502] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,511] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,515] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,515] INFO Instantiated task QuestIntegration-2 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,516] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,517] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,518] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-2 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,518] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-2 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,519] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-2 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,524] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,526] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,528] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,531] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,576] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,577] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,578] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,579] INFO Kafka startTimeMs: 1613972357577 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,610] INFO Creating task QuestIntegration-3 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,612] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,614] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,620] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,623] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,624] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,627] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,639] INFO Instantiated task QuestIntegration-3 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,641] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,642] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,643] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-3 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,643] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-3 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,644] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-3 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,663] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,668] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,669] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,673] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,712] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,713] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,714] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,715] INFO Kafka startTimeMs: 1613972357713 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,727] INFO Creating task QuestIntegration-4 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,731] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,736] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,737] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,743] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,755] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,763] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,764] INFO Instantiated task QuestIntegration-4 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,765] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,766] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,766] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-4 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,767] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-4 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,767] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-4 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,773] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,774] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,776] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,780] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,806] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,807] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,808] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,809] INFO Kafka startTimeMs: 1613972357807 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,823] INFO Creating task QuestIntegration-5 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,828] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,830] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,832] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,833] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,834] INFO Instantiated task QuestIntegration-5 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,833] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,836] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,837] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,839] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,840] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-5 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,841] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-5 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,842] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-5 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,848] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,850] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,852] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,856] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:17,882] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:17,883] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:17,884] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:17,885] INFO Kafka startTimeMs: 1613972357883 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:17,960] INFO Creating task QuestIntegration-6 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:17,966] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:17,967] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:17,969] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,973] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:17,973] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:17,974] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:17,975] INFO Instantiated task QuestIntegration-6 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:17,977] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,978] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:17,979] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-6 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:17,979] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-6 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:17,980] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-6 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:17,985] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:17,988] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:17,990] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:17,993] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:18,032] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:18,034] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:18,035] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:18,036] INFO Kafka startTimeMs: 1613972358034 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:18,053] INFO Creating task QuestIntegration-7 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:18,058] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:18,062] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:18,063] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:18,066] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:18,068] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,070] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:18,071] INFO Instantiated task QuestIntegration-7 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:18,072] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,074] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,075] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-7 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:18,075] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-7 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:18,076] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-7 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:18,080] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:18,082] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:18,089] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,092] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:18,126] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:18,128] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:18,128] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:18,129] INFO Kafka startTimeMs: 1613972358127 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:18,141] INFO Creating task QuestIntegration-8 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:18,143] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:18,151] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:18,152] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:18,152] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:18,153] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,158] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:18,159] INFO Instantiated task QuestIntegration-8 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:18,159] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,160] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,161] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-8 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:18,162] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-8 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:18,163] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-8 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:18,173] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:18,178] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:18,183] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,187] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:18,211] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:18,211] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:18,212] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:18,213] INFO Kafka startTimeMs: 1613972358211 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:18,223] INFO Creating task QuestIntegration-9 (org.apache.kafka.connect.runtime.Worker:509)
[2021-02-22 00:39:18,226] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:18,233] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:18,234] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:361)
[2021-02-22 00:39:18,234] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:18,237] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,239] INFO TaskConfig values: 
	task.class = class rockset.RocksetSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:361)
[2021-02-22 00:39:18,239] INFO Instantiated task QuestIntegration-9 with version 0.0.0.0 of type rockset.RocksetSinkTask (org.apache.kafka.connect.runtime.Worker:524)
[2021-02-22 00:39:18,240] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,240] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = value
 (org.apache.kafka.connect.storage.StringConverterConfig:361)
[2021-02-22 00:39:18,241] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-9 using the connector config (org.apache.kafka.connect.runtime.Worker:539)
[2021-02-22 00:39:18,241] INFO Set up the value converter class org.apache.kafka.connect.storage.StringConverter for task QuestIntegration-9 using the connector config (org.apache.kafka.connect.runtime.Worker:545)
[2021-02-22 00:39:18,242] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task QuestIntegration-9 using the worker config (org.apache.kafka.connect.runtime.Worker:550)
[2021-02-22 00:39:18,248] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:632)
[2021-02-22 00:39:18,250] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:361)
[2021-02-22 00:39:18,252] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = rockset.RocksetSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = QuestIntegration
	predicates = []
	tasks.max = 10
	topics = [questTopic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.storage.StringConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:361)
[2021-02-22 00:39:18,255] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-ep9mm.us-east-2.aws.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-QuestIntegration-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-QuestIntegration
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = PLAIN
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:361)
[2021-02-22 00:39:18,285] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2021-02-22 00:39:18,286] INFO Kafka version: 2.7.0 (org.apache.kafka.common.utils.AppInfoParser:119)
[2021-02-22 00:39:18,286] INFO Kafka commitId: 448719dc99a19793 (org.apache.kafka.common.utils.AppInfoParser:120)
[2021-02-22 00:39:18,287] INFO Kafka startTimeMs: 1613972358286 (org.apache.kafka.common.utils.AppInfoParser:121)
[2021-02-22 00:39:18,306] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Subscribed to topic(s): questTopic (org.apache.kafka.clients.consumer.KafkaConsumer:961)
[2021-02-22 00:39:18,311] INFO RocksetConnectorConfig values: 
	format = JSON
	rockset.apikey = null
	rockset.apiserver.url = https://api.rs2.usw2.rockset.com
	rockset.collection = null
	rockset.integration.key = kafka://xV0V5hVoYDe7fdlgfDM3gkmbWNTj4BRh1Xx5wGaHKKQ4Sm1d1WAdIqFmx93vbi79@api.rs2.usw2.rockset.com
	rockset.task.threads = 5
	rockset.workspace = commons
 (rockset.RocksetConnectorConfig:361)
[2021-02-22 00:39:18,311] INFO Created connector QuestIntegration (org.apache.kafka.connect.cli.ConnectStandalone:112)
[2021-02-22 00:39:18,311] INFO Building Rockset connector config. Apiserver: https://api.rs2.usw2.rockset.comNumber of Threads: 5, Format: JSON (rockset.RocksetConnectorConfig:30)
[2021-02-22 00:39:18,442] INFO WorkerSinkTask{id=QuestIntegration-8} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,442] INFO WorkerSinkTask{id=QuestIntegration-1} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,443] INFO WorkerSinkTask{id=QuestIntegration-4} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,443] INFO WorkerSinkTask{id=QuestIntegration-3} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,442] INFO WorkerSinkTask{id=QuestIntegration-7} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,444] INFO WorkerSinkTask{id=QuestIntegration-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,444] INFO WorkerSinkTask{id=QuestIntegration-2} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,444] INFO WorkerSinkTask{id=QuestIntegration-5} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,442] INFO WorkerSinkTask{id=QuestIntegration-9} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:18,444] INFO WorkerSinkTask{id=QuestIntegration-6} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:309)
[2021-02-22 00:39:19,557] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,557] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,557] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,563] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,563] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,563] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,568] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,585] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,607] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,690] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,692] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,692] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,692] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,694] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,695] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,695] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:19,924] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:19,925] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:20,130] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Cluster ID: lkc-863j0 (org.apache.kafka.clients.Metadata:279)
[2021-02-22 00:39:20,132] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Discovered group coordinator b0-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:847)
[2021-02-22 00:39:22,018] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,021] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,020] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,020] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,019] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,027] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,029] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,032] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,039] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,041] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,849] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,849] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,849] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,886] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:22,890] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:22,902] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Finished assignment for group at generation 1: {connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55=Assignment(partitions=[questTopic-0, questTopic-1])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:39:23,003] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,006] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,032] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:781)
[2021-02-22 00:39:23,036] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Rebalance failed. (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:472)
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
[2021-02-22 00:39:23,045] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,044] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,044] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,057] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,057] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2021-02-22 00:39:23,095] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-8-50f86e8e-d9aa-4e3d-aede-43acf78bb929', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,096] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-1-afdb5bec-84ef-43df-8dd7-dcfda11af863', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,097] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-9-5c3d414a-150d-4d32-9629-22286ddc6ac5', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,096] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-7-25301f34-5a3b-423a-ad74-99dfaca06606', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,095] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-2-8bc947dc-483b-4bb5-b3b4-fafd0715b9c7', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,095] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-3-ea1a6468-6bd7-4e5b-9c05-e2c39c3c12de', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,098] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-4-b1f660de-2cf9-4b55-9f52-0ad2c465d959', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,097] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,097] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-6-b5034b49-3ebc-42c2-a88d-f3ac2e6d11da', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,097] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-5-eb7d0051-ce8d-404a-acd6-4661c385325e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2021-02-22 00:39:23,135] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Finished assignment for group at generation 2: {connector-consumer-QuestIntegration-6-b5034b49-3ebc-42c2-a88d-f3ac2e6d11da=Assignment(partitions=[]), connector-consumer-QuestIntegration-7-25301f34-5a3b-423a-ad74-99dfaca06606=Assignment(partitions=[]), connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55=Assignment(partitions=[questTopic-0]), connector-consumer-QuestIntegration-1-afdb5bec-84ef-43df-8dd7-dcfda11af863=Assignment(partitions=[questTopic-1]), connector-consumer-QuestIntegration-3-ea1a6468-6bd7-4e5b-9c05-e2c39c3c12de=Assignment(partitions=[]), connector-consumer-QuestIntegration-4-b1f660de-2cf9-4b55-9f52-0ad2c465d959=Assignment(partitions=[]), connector-consumer-QuestIntegration-2-8bc947dc-483b-4bb5-b3b4-fafd0715b9c7=Assignment(partitions=[]), connector-consumer-QuestIntegration-8-50f86e8e-d9aa-4e3d-aede-43acf78bb929=Assignment(partitions=[]), connector-consumer-QuestIntegration-9-5c3d414a-150d-4d32-9629-22286ddc6ac5=Assignment(partitions=[]), connector-consumer-QuestIntegration-5-eb7d0051-ce8d-404a-acd6-4661c385325e=Assignment(partitions=[])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-2-8bc947dc-483b-4bb5-b3b4-fafd0715b9c7', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-6-b5034b49-3ebc-42c2-a88d-f3ac2e6d11da', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-4-b1f660de-2cf9-4b55-9f52-0ad2c465d959', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-7-25301f34-5a3b-423a-ad74-99dfaca06606', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-1-afdb5bec-84ef-43df-8dd7-dcfda11af863', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,374] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,368] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-8-50f86e8e-d9aa-4e3d-aede-43acf78bb929', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,375] INFO [Consumer clientId=connector-consumer-QuestIntegration-6, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,374] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-0-7c5ff20e-9c74-45aa-b124-6758bca3ee55', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,374] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,377] INFO [Consumer clientId=connector-consumer-QuestIntegration-7, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,373] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,372] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,371] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-9-5c3d414a-150d-4d32-9629-22286ddc6ac5', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,371] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-5-eb7d0051-ce8d-404a-acd6-4661c385325e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,381] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,382] INFO [Consumer clientId=connector-consumer-QuestIntegration-9, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,369] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-QuestIntegration-3-ea1a6468-6bd7-4e5b-9c05-e2c39c3c12de', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2021-02-22 00:39:23,384] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,382] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,380] INFO [Consumer clientId=connector-consumer-QuestIntegration-2, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,378] INFO [Consumer clientId=connector-consumer-QuestIntegration-4, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,377] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[questTopic-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,376] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,375] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Notifying assignor about the new Assignment(partitions=[questTopic-1]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2021-02-22 00:39:23,393] INFO [Consumer clientId=connector-consumer-QuestIntegration-8, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,386] INFO [Consumer clientId=connector-consumer-QuestIntegration-3, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,386] INFO [Consumer clientId=connector-consumer-QuestIntegration-5, groupId=connect-QuestIntegration] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,409] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Adding newly assigned partitions: questTopic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,409] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Adding newly assigned partitions: questTopic-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2021-02-22 00:39:23,466] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Found no committed offset for partition questTopic-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-02-22 00:39:23,466] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Found no committed offset for partition questTopic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1354)
[2021-02-22 00:39:24,262] INFO [Consumer clientId=connector-consumer-QuestIntegration-1, groupId=connect-QuestIntegration] Resetting offset for partition questTopic-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b1-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 1 rack: 1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-02-22 00:39:25,426] INFO [Consumer clientId=connector-consumer-QuestIntegration-0, groupId=connect-QuestIntegration] Resetting offset for partition questTopic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[b5-pkc-ep9mm.us-east-2.aws.confluent.cloud:9092 (id: 5 rack: 2)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2021-02-22 00:39:27,372] INFO WorkerSinkTask{id=QuestIntegration-0} Committing offsets asynchronously using sequence number 1: {questTopic-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-02-22 00:41:57,487] INFO WorkerSinkTask{id=QuestIntegration-1} Committing offsets asynchronously using sequence number 16: {questTopic-1=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-02-22 00:43:17,497] INFO WorkerSinkTask{id=QuestIntegration-1} Committing offsets asynchronously using sequence number 24: {questTopic-1=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
[2021-02-22 00:50:47,451] INFO WorkerSinkTask{id=QuestIntegration-0} Committing offsets asynchronously using sequence number 69: {questTopic-0=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask:352)
